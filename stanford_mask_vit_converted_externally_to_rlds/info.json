{
  "repr": "tfds.core.DatasetInfo(\n    name='stanford_mask_vit_converted_externally_to_rlds',\n    full_name='stanford_mask_vit_converted_externally_to_rlds/0.1.0',\n    description=\"\"\"\n    Sawyer pushing and picking objects in a bin\n    \"\"\",\n    homepage='https://arxiv.org/abs/2206.11894',\n    data_path='gs://gresearch/robotics/stanford_mask_vit_converted_externally_to_rlds/0.1.0',\n    file_format=tfrecord,\n    download_size=Unknown size,\n    dataset_size=76.17 GiB,\n    features=FeaturesDict({\n        'episode_metadata': FeaturesDict({\n            'file_path': Text(shape=(), dtype=string),\n        }),\n        'steps': Dataset({\n            'action': Tensor(shape=(5,), dtype=float32),\n            'discount': Scalar(shape=(), dtype=float32),\n            'is_first': bool,\n            'is_last': bool,\n            'is_terminal': bool,\n            'language_embedding': Tensor(shape=(512,), dtype=float32),\n            'language_instruction': Text(shape=(), dtype=string),\n            'observation': FeaturesDict({\n                'end_effector_pose': Tensor(shape=(5,), dtype=float32),\n                'finger_sensors': Tensor(shape=(1,), dtype=float32),\n                'high_bound': Tensor(shape=(5,), dtype=float32),\n                'image': Image(shape=(480, 480, 3), dtype=uint8),\n                'low_bound': Tensor(shape=(5,), dtype=float32),\n                'state': Tensor(shape=(15,), dtype=float32),\n            }),\n            'reward': Scalar(shape=(), dtype=float32),\n        }),\n    }),\n    supervised_keys=None,\n    disable_shuffling=False,\n    splits={\n        'train': <SplitInfo num_examples=9109, num_shards=1023>,\n        'val': <SplitInfo num_examples=91, num_shards=8>,\n    },\n    citation=\"\"\"@inproceedings{gupta2022maskvit,\n      title={MaskViT: Masked Visual Pre-Training for Video Prediction},\n      author={Agrim Gupta and Stephen Tian and Yunzhi Zhang and Jiajun Wu and Roberto Mart\u00edn-Mart\u00edn and Li Fei-Fei},\n      booktitle={International Conference on Learning Representations},\n      year={2022}\n    }\"\"\",\n)",
  "size": "76.17 GiB",
  "n_traj": 9109,
  "image_keys": {
    "image": [
      480,
      480,
      3
    ]
  },
  "depth_keys": {},
  "text_keys": []
}